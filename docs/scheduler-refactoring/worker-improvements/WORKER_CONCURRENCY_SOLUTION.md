# Worker å•æœºå¹¶å‘æ‰§è¡Œæ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜åˆ†æ

### å½“å‰é—®é¢˜
- Worker ä¸€æ¬¡åªèƒ½è¿è¡Œä¸€ä¸ªä»»åŠ¡ï¼ˆå•è¿›ç¨‹å•çº¿ç¨‹ï¼‰
- å³ä½¿æœ‰è¶³å¤Ÿçš„ CPU èµ„æºï¼Œä¹Ÿæ— æ³•å¹¶å‘æ‰§è¡Œå¤šä¸ªä½œä¸š
- ä½œä¸šå¿…é¡»ä¸²è¡Œæ‰§è¡Œï¼Œå¯¼è‡´èµ„æºåˆ©ç”¨ç‡ä½

### æ ¹æœ¬åŸå› 
RQ Worker é»˜è®¤æ˜¯**å•è¿›ç¨‹å•çº¿ç¨‹**çš„ï¼š
```python
# å½“å‰å®ç°
worker = Worker([queue])
worker.work()  # é˜»å¡æ‰§è¡Œï¼Œä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªä»»åŠ¡
```

æ‰§è¡Œæµç¨‹ï¼š
```
Redis é˜Ÿåˆ—: [Job1, Job2, Job3, Job4]
               â†“
          RQ Worker (å•è¿›ç¨‹)
               â†“
æ‰§è¡Œ Job1 â†’ fork å­è¿›ç¨‹ â†’ ç­‰å¾…å®Œæˆï¼ˆé˜»å¡ï¼‰
  â†“
Job1 å®Œæˆåæ‰æ‰§è¡Œ Job2  â† ä¸²è¡Œæ‰§è¡Œï¼
```

## ğŸ¯ è§£å†³æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ 1: å¤šè¿›ç¨‹ Workerï¼ˆæ¨èï¼‰â­

**åŸç†**ï¼šå¯åŠ¨å¤šä¸ªç‹¬ç«‹çš„ Worker è¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹ä»åŒä¸€ä¸ª Redis é˜Ÿåˆ—å–ä»»åŠ¡ã€‚

```
                    Redis é˜Ÿåˆ—: [Job1, Job2, Job3, Job4]
                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                  â†“                  â†“                  â†“
   Worker-1           Worker-2           Worker-3           Worker-4
        â†“                  â†“                  â†“                  â†“
   æ‰§è¡Œ Job1          æ‰§è¡Œ Job2          æ‰§è¡Œ Job3          æ‰§è¡Œ Job4
        â†“                  â†“                  â†“                  â†“
   å¹¶å‘æ‰§è¡Œï¼        å¹¶å‘æ‰§è¡Œï¼        å¹¶å‘æ‰§è¡Œï¼        å¹¶å‘æ‰§è¡Œï¼
```

**ä¼˜ç‚¹**ï¼š
- âœ… çœŸæ­£çš„å¹¶å‘æ‰§è¡Œï¼ˆå¤šè¿›ç¨‹ï¼Œä¸å— Python GIL é™åˆ¶ï¼‰
- âœ… å……åˆ†åˆ©ç”¨å¤šæ ¸ CPU
- âœ… è¿›ç¨‹éš”ç¦»ï¼Œä¸€ä¸ª Worker å´©æºƒä¸å½±å“å…¶ä»–
- âœ… ç¬¦åˆ RQ çš„è®¾è®¡ç†å¿µ
- âœ… èµ„æºç®¡ç†æ¸…æ™°ï¼ˆæ¯ä¸ª Worker ç‹¬ç«‹ç®¡ç†èµ„æºï¼‰

**ç¼ºç‚¹**ï¼š
- âš ï¸ éœ€è¦ç®¡ç†å¤šä¸ªè¿›ç¨‹
- âš ï¸ èµ„æºå ç”¨ç¨é«˜ï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹çš„å†…å­˜ç©ºé—´ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š**æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ**

---

### æ–¹æ¡ˆ 2: RQ Worker Poolï¼ˆä¸æ¨èï¼‰

**åŸç†**ï¼šä½¿ç”¨ RQ çš„ worker pool åŠŸèƒ½ï¼ˆå¦‚æœæ”¯æŒï¼‰ã€‚

**é—®é¢˜**ï¼š
- âŒ RQ æ ‡å‡†ç‰ˆæœ¬ä¸æ”¯æŒ worker pool
- âŒ éœ€è¦ç¬¬ä¸‰æ–¹æ‰©å±•æˆ–è‡ªå®šä¹‰å®ç°
- âŒ å…¼å®¹æ€§å’Œç¨³å®šæ€§æœªçŸ¥

**ç»“è®º**ï¼š**ä¸æ¨èä½¿ç”¨**

---

### æ–¹æ¡ˆ 3: çº¿ç¨‹æ± /è¿›ç¨‹æ± ï¼ˆä¸æ¨èï¼‰

**åŸç†**ï¼šåœ¨å•ä¸ª Worker ä¸­ä½¿ç”¨çº¿ç¨‹æ± æˆ–è¿›ç¨‹æ± ã€‚

**é—®é¢˜**ï¼š
- âŒ çº¿ç¨‹å— Python GIL é™åˆ¶ï¼Œæ— æ³•çœŸæ­£å¹¶å‘æ‰§è¡Œ CPU å¯†é›†å‹ä»»åŠ¡
- âŒ è¿›ç¨‹æ± éœ€è¦é¢å¤–ç®¡ç†ï¼Œå¤æ‚åº¦é«˜
- âŒ ä¸ RQ çš„è®¾è®¡ç†å¿µä¸ç¬¦

**ç»“è®º**ï¼š**ä¸æ¨èä½¿ç”¨**

---

## âœ… æ¨èæ–¹æ¡ˆï¼šå¤šè¿›ç¨‹ Worker

### æ¶æ„è®¾è®¡

```
ä¸»è¿›ç¨‹ (worker/main.py)
    â”‚
    â”œâ”€ åˆå§‹åŒ–ï¼ˆæ•°æ®åº“ã€Redisã€æ³¨å†Œï¼‰
    â”‚
    â”œâ”€ å¯åŠ¨ N ä¸ª Worker å­è¿›ç¨‹
    â”‚   â”œâ”€ Worker-1 (PID: 1001)
    â”‚   â”œâ”€ Worker-2 (PID: 1002)
    â”‚   â”œâ”€ Worker-3 (PID: 1003)
    â”‚   â””â”€ Worker-N (PID: 100N)
    â”‚
    â””â”€ ç›‘æ§å’Œä¿¡å·å¤„ç†
```

### å®ç°æ–¹æ¡ˆ

#### 1. ä¿®æ”¹ `worker/main.py`

```python
"""
Worker Service - ä¸»å…¥å£ï¼ˆæ”¯æŒå¤šè¿›ç¨‹å¹¶å‘ï¼‰

æ”¯æŒé€šè¿‡ WORKER_CONCURRENCY é…ç½®å¯åŠ¨å¤šä¸ª Worker è¿›ç¨‹
"""

import sys
import signal
import multiprocessing
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger

from core.config import get_settings
from core.database import sync_db
from core.redis_client import redis_manager
from core.utils.logger import setup_logger
from worker.registry import WorkerRegistry


def run_worker_process(worker_id: int, settings_dict: dict):
    """
    è¿è¡Œå•ä¸ª Worker è¿›ç¨‹
    
    Args:
        worker_id: Worker ID (1, 2, 3, ...)
        settings_dict: é…ç½®å­—å…¸ï¼ˆç”¨äºå­è¿›ç¨‹ï¼‰
    """
    import os
    
    # é‡æ–°åˆå§‹åŒ–é…ç½®ï¼ˆå­è¿›ç¨‹éœ€è¦ï¼‰
    from core.config import Settings
    settings = Settings(**settings_dict)
    
    # è®¾ç½®æ—¥å¿—
    setup_logger(settings.LOG_LEVEL, settings.LOG_FILE)
    
    logger.info(f"ğŸš€ Worker-{worker_id} started (PID: {os.getpid()})")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        sync_db.init()
        
        # åˆå§‹åŒ– Redis
        redis_manager.init()
        if not redis_manager.ping():
            raise ConnectionError("Redis not available")
        
        # è·å–é˜Ÿåˆ—
        queue = redis_manager.get_queue()
        
        # åˆå§‹åŒ– Worker æ³¨å†Œå™¨ï¼ˆæ¯ä¸ª Worker ç‹¬ç«‹æ³¨å†Œï¼‰
        registry = WorkerRegistry()
        
        # æ³¨å†Œ Workerï¼ˆä½¿ç”¨å”¯ä¸€çš„ worker_idï¼‰
        worker_name = f"worker-{settings.NODE_NAME}-{worker_id}"
        if not registry.register():
            logger.error(f"âœ— Worker-{worker_id} registration failed")
            sys.exit(1)
        
        # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
        if not registry.start_heartbeat():
            logger.error(f"âœ— Worker-{worker_id} failed to start heartbeat")
            sys.exit(1)
        
        # æ¸…ç†è¿‡æœŸçš„ RQ worker
        connection = redis_manager.get_connection()
        from rq.worker import Worker as RQWorker
        
        all_workers = RQWorker.all(connection=connection)
        for w in all_workers:
            if w.name == worker_name:
                try:
                    w.refresh()
                    if not w.is_alive():
                        logger.warning(f"ğŸ§¹ Cleaning up dead worker: {worker_name}")
                        w.register_death()
                except Exception as e:
                    logger.warning(f"ğŸ§¹ Cleaning up stale worker: {worker_name} - {e}")
                    w.register_death()
        
        # åˆ›å»º RQ Worker
        worker = RQWorker(
            [queue],
            connection=connection,
            name=worker_name,
        )
        
        logger.info(f"âœ… Worker-{worker_id} is ready, waiting for jobs...")
        
        # è¿è¡Œ Workerï¼ˆé˜»å¡ï¼‰
        worker.work(burst=settings.WORKER_BURST, with_scheduler=False)
        
    except KeyboardInterrupt:
        logger.info(f"âš ï¸  Worker-{worker_id} interrupted by user")
    except Exception as e:
        logger.error(f"âŒ Worker-{worker_id} error: {e}", exc_info=True)
    finally:
        # æ³¨é”€ Worker
        logger.info(f"Shutting down Worker-{worker_id}...")
        registry.unregister()
        
        # å…³é—­è¿æ¥
        sync_db.close()
        redis_manager.close()
        
        logger.info(f"âœ… Worker-{worker_id} stopped")


def main():
    """Worker æœåŠ¡ä¸»å…¥å£ï¼ˆæ”¯æŒå¤šè¿›ç¨‹ï¼‰"""
    settings = get_settings()
    setup_logger(settings.LOG_LEVEL, settings.LOG_FILE)
    
    logger.info("=" * 70)
    logger.info("ğŸ’ª SCNS-Conductor Worker Service v2.1 (Multi-Process)")
    logger.info("=" * 70)
    
    # è·å–å¹¶å‘æ•°
    concurrency = settings.WORKER_CONCURRENCY
    
    if concurrency < 1:
        logger.error("WORKER_CONCURRENCY must be >= 1")
        sys.exit(1)
    
    logger.info("-" * 70)
    logger.info(f"Node: {settings.NODE_NAME}")
    logger.info(f"Total CPUs: {settings.TOTAL_CPUS}")
    logger.info(f"Worker Concurrency: {concurrency}")
    logger.info("-" * 70)
    
    # éªŒè¯å¹¶å‘æ•°åˆç†æ€§
    if concurrency > settings.TOTAL_CPUS:
        logger.warning(
            f"âš ï¸  WORKER_CONCURRENCY ({concurrency}) > TOTAL_CPUS ({settings.TOTAL_CPUS}), "
            f"may cause resource contention"
        )
    
    # å°†é…ç½®è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºä¼ é€’ç»™å­è¿›ç¨‹ï¼‰
    settings_dict = settings.model_dump()
    
    # å¦‚æœå¹¶å‘æ•°ä¸º 1ï¼Œç›´æ¥è¿è¡Œï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
    if concurrency == 1:
        logger.info("Running in single-worker mode")
        run_worker_process(1, settings_dict)
        return
    
    # å¤šè¿›ç¨‹æ¨¡å¼
    logger.info(f"ğŸš€ Starting {concurrency} worker processes...")
    
    # åˆ›å»ºè¿›ç¨‹åˆ—è¡¨
    processes = []
    
    # ä¿¡å·å¤„ç†
    def signal_handler(signum, frame):
        logger.info(f"ğŸ›‘ Received signal {signum}, shutting down all workers...")
        for p in processes:
            if p.is_alive():
                p.terminate()
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
        for p in processes:
            p.join(timeout=5)
            if p.is_alive():
                logger.warning(f"Process {p.pid} did not terminate, killing...")
                p.kill()
        sys.exit(0)
    
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    # å¯åŠ¨å¤šä¸ª Worker è¿›ç¨‹
    for i in range(1, concurrency + 1):
        p = multiprocessing.Process(
            target=run_worker_process,
            args=(i, settings_dict),
            name=f"Worker-{i}",
        )
        p.start()
        processes.append(p)
        logger.info(f"âœ“ Worker-{i} process started (PID: {p.pid})")
    
    logger.info("=" * 70)
    logger.info(f"âœ… {concurrency} worker processes are ready, waiting for jobs...")
    logger.info("=" * 70)
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
    try:
        for p in processes:
            p.join()
    except KeyboardInterrupt:
        signal_handler(signal.SIGINT, None)


if __name__ == "__main__":
    main()
```

#### 2. ä¿®æ”¹ Worker æ³¨å†Œï¼ˆæ”¯æŒå¤šå®ä¾‹ï¼‰

éœ€è¦ç¡®ä¿æ¯ä¸ª Worker è¿›ç¨‹éƒ½æœ‰å”¯ä¸€çš„æ ‡è¯†ï¼š

```python
# worker/registry.py
class WorkerRegistry:
    def __init__(self, worker_id: Optional[int] = None, ...):
        # å¦‚æœæä¾›äº† worker_idï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤çš„ NODE_NAME
        if worker_id:
            self.worker_id = f"{self.settings.NODE_NAME}-{worker_id}"
        else:
            self.worker_id = self.settings.NODE_NAME
        # ...
```

#### 3. èµ„æºç®¡ç†è€ƒè™‘

**é‡è¦**ï¼šæ¯ä¸ª Worker è¿›ç¨‹éƒ½ä¼šï¼š
- ç‹¬ç«‹æ³¨å†Œåˆ° Redisï¼ˆä½¿ç”¨å”¯ä¸€çš„ worker_idï¼‰
- ç‹¬ç«‹ç®¡ç†èµ„æºåˆ†é…
- ç‹¬ç«‹å‘é€å¿ƒè·³

**èµ„æºåˆ†é…é€»è¾‘**ï¼š
- Scheduler æ ¹æ® `TOTAL_CPUS` å’Œå·²åˆ†é…çš„ CPU æ•°é‡è¿›è¡Œè°ƒåº¦
- æ¯ä¸ª Worker è¿›ç¨‹æ‰§è¡Œä½œä¸šæ—¶ï¼Œä¼šæ›´æ–°èµ„æºçŠ¶æ€
- å¤šä¸ª Worker å¹¶å‘æ‰§è¡Œæ—¶ï¼Œèµ„æºç®¡ç†å™¨ä¼šè‡ªåŠ¨è·Ÿè¸ªæ€»ä½¿ç”¨é‡

**ç¤ºä¾‹**ï¼š
```
TOTAL_CPUS = 32
WORKER_CONCURRENCY = 4

Worker-1 æ‰§è¡Œ Job1 (4 CPUs) â†’ å·²ç”¨: 4/32
Worker-2 æ‰§è¡Œ Job2 (8 CPUs) â†’ å·²ç”¨: 12/32
Worker-3 æ‰§è¡Œ Job3 (4 CPUs) â†’ å·²ç”¨: 16/32
Worker-4 æ‰§è¡Œ Job4 (8 CPUs) â†’ å·²ç”¨: 24/32
å‰©ä½™: 8 CPUs
```

---

## ğŸ“ é…ç½®è¯´æ˜

### é…ç½®æ–‡ä»¶ (`app.properties`)

```properties
# Worker Configuration
WORKER_CONCURRENCY=4  # å¯åŠ¨ 4 ä¸ª Worker è¿›ç¨‹
WORKER_BURST=false

# Resource Configuration
NODE_NAME=kunpeng-compute-01
TOTAL_CPUS=32
```

### é…ç½®å»ºè®®

**å¹¶å‘æ•°é€‰æ‹©åŸåˆ™**ï¼š
1. **ä¸è¶…è¿‡ CPU æ ¸å¿ƒæ•°**ï¼š`WORKER_CONCURRENCY <= TOTAL_CPUS`
2. **è€ƒè™‘ä½œä¸š CPU éœ€æ±‚**ï¼š`WORKER_CONCURRENCY <= TOTAL_CPUS / æœ€å°ä½œä¸šCPUéœ€æ±‚`
3. **ç•™æœ‰ä½™é‡**ï¼šå»ºè®® `WORKER_CONCURRENCY <= TOTAL_CPUS * 0.8`

**ç¤ºä¾‹é…ç½®**ï¼š
- 32 æ ¸ç³»ç»Ÿï¼Œæ¯ä¸ªä½œä¸šè‡³å°‘ 4 æ ¸ â†’ å»ºè®® `WORKER_CONCURRENCY = 4-8`
- 64 æ ¸ç³»ç»Ÿï¼Œæ¯ä¸ªä½œä¸šè‡³å°‘ 2 æ ¸ â†’ å»ºè®® `WORKER_CONCURRENCY = 8-16`
- 16 æ ¸ç³»ç»Ÿï¼Œæ¯ä¸ªä½œä¸šè‡³å°‘ 4 æ ¸ â†’ å»ºè®® `WORKER_CONCURRENCY = 2-4`

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### 1. å¯åŠ¨ Worker

```bash
# å¯åŠ¨å¤šè¿›ç¨‹ Workerï¼ˆè‡ªåŠ¨è¯»å– WORKER_CONCURRENCYï¼‰
python worker/main.py
```

**æ—¥å¿—è¾“å‡º**ï¼š
```
======================================================================
ğŸ’ª SCNS-Conductor Worker Service v2.1 (Multi-Process)
======================================================================
----------------------------------------------------------------------
Node: kunpeng-compute-01
Total CPUs: 32
Worker Concurrency: 4
----------------------------------------------------------------------
ğŸš€ Starting 4 worker processes...
âœ“ Worker-1 process started (PID: 12345)
âœ“ Worker-2 process started (PID: 12346)
âœ“ Worker-3 process started (PID: 12347)
âœ“ Worker-4 process started (PID: 12348)
======================================================================
âœ… 4 worker processes are ready, waiting for jobs...
======================================================================
```

### 2. éªŒè¯å¹¶å‘æ‰§è¡Œ

**æäº¤å¤šä¸ªä½œä¸š**ï¼š
```bash
# å¿«é€Ÿæäº¤ 4 ä¸ªä½œä¸š
for i in {1..4}; do
  curl -X POST http://localhost:8000/api/v1/jobs/submit \
    -H "Content-Type: application/json" \
    -d '{
      "job": {
        "account": "test",
        "name": "concurrent-job-'$i'",
        "partition": "compute-high-mem",
        "ntasks_per_node": 1,
        "cpus_per_task": 4,
        "memory_per_node": "8G"
      },
      "script": "#!/bin/bash\necho \"Job '$i' is running\"\nsleep 10"
    }'
done
```

**è§‚å¯Ÿæ‰§è¡Œ**ï¼š
- æŸ¥çœ‹æ•°æ®åº“ï¼š4 ä¸ªä½œä¸šåº”è¯¥**åŒæ—¶**å¤„äº `RUNNING` çŠ¶æ€
- æŸ¥çœ‹æ—¥å¿—ï¼š4 ä¸ª Worker å„è‡ªå¤„ç†ä¸€ä¸ªä½œä¸š
- æŸ¥çœ‹è¿›ç¨‹ï¼šåº”è¯¥æœ‰ 4 ä¸ªç‹¬ç«‹çš„ Worker è¿›ç¨‹åœ¨è¿è¡Œ

---

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### 1. æŸ¥çœ‹ Worker è¿›ç¨‹

```bash
# æŸ¥çœ‹æ‰€æœ‰ Worker è¿›ç¨‹
ps aux | grep "worker/main.py"

# æŸ¥çœ‹è¿›ç¨‹æ ‘
pstree -p | grep worker
```

### 2. æŸ¥çœ‹ Redis Worker æ³¨å†Œ

```bash
# è¿æ¥åˆ° Redis
redis-cli

# æŸ¥çœ‹æ‰€æœ‰ Worker
KEYS worker:*

# æŸ¥çœ‹ Worker è¯¦æƒ…
HGETALL worker:kunpeng-compute-01-1
```

### 3. æŸ¥çœ‹æ—¥å¿—

æ¯ä¸ª Worker è¿›ç¨‹ä¼šè¾“å‡ºç‹¬ç«‹çš„æ—¥å¿—ï¼š
```
[Worker-1] ğŸš€ Executing job 123
[Worker-2] ğŸš€ Executing job 124
[Worker-3] ğŸš€ Executing job 125
[Worker-4] ğŸš€ Executing job 126
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. èµ„æºç®¡ç†
- ç¡®ä¿ `WORKER_CONCURRENCY` ä¸è¶…è¿‡ `TOTAL_CPUS`
- è€ƒè™‘ä½œä¸šçš„ CPU éœ€æ±‚ï¼Œé¿å…è¿‡åº¦å¹¶å‘å¯¼è‡´èµ„æºç«äº‰

### 2. è¿›ç¨‹ç®¡ç†
- ä¸»è¿›ç¨‹è´Ÿè´£å¯åŠ¨å’Œç›‘æ§å­è¿›ç¨‹
- ä½¿ç”¨ä¿¡å·å¤„ç†ç¡®ä¿ä¼˜é›…å…³é—­
- å­è¿›ç¨‹å´©æºƒæ—¶ï¼Œä¸»è¿›ç¨‹å¯ä»¥æ£€æµ‹å¹¶é‡å¯ï¼ˆå¯é€‰ï¼‰

### 3. æ•°æ®åº“è¿æ¥
- æ¯ä¸ª Worker è¿›ç¨‹éœ€è¦ç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥
- ç¡®ä¿æ•°æ®åº“è¿æ¥æ± è¶³å¤Ÿå¤§

### 4. Redis è¿æ¥
- æ¯ä¸ª Worker è¿›ç¨‹éœ€è¦ç‹¬ç«‹çš„ Redis è¿æ¥
- RQ ä¼šè‡ªåŠ¨ç®¡ç† Redis è¿æ¥

### 5. æ—¥å¿—ç®¡ç†
- å¤šä¸ªè¿›ç¨‹å¯èƒ½åŒæ—¶å†™å…¥æ—¥å¿—æ–‡ä»¶
- å»ºè®®ä½¿ç”¨è¿›ç¨‹å®‰å…¨çš„æ—¥å¿—å¤„ç†å™¨ï¼ˆloguru å·²æ”¯æŒï¼‰

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å• Workerï¼ˆå½“å‰ï¼‰
- å¹¶å‘èƒ½åŠ›ï¼š1 ä¸ªä½œä¸š
- CPU åˆ©ç”¨ç‡ï¼šä½ï¼ˆå•æ ¸ï¼‰
- ååé‡ï¼šä½

### å¤š Workerï¼ˆæ¨èï¼‰
- å¹¶å‘èƒ½åŠ›ï¼šN ä¸ªä½œä¸šï¼ˆN = WORKER_CONCURRENCYï¼‰
- CPU åˆ©ç”¨ç‡ï¼šé«˜ï¼ˆå¤šæ ¸ï¼‰
- ååé‡ï¼šé«˜ï¼ˆN å€æå‡ï¼‰

**ç¤ºä¾‹**ï¼š
- 4 ä¸ª Workerï¼Œæ¯ä¸ªä½œä¸šæ‰§è¡Œ 10 ç§’
- å• Workerï¼š40 ç§’å®Œæˆ 4 ä¸ªä½œä¸š
- å¤š Workerï¼š10 ç§’å®Œæˆ 4 ä¸ªä½œä¸šï¼ˆ4 å€æå‡ï¼‰

---

## ğŸ”„ ä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§

### å…¼å®¹æ€§æ£€æŸ¥

âœ… **å®Œå…¨å…¼å®¹**ï¼š
- Scheduler æ— éœ€ä¿®æ”¹ï¼ˆè‡ªåŠ¨é€‚é…ï¼‰
- ResourceManager æ— éœ€ä¿®æ”¹ï¼ˆè‡ªåŠ¨è·Ÿè¸ªï¼‰
- API æ— éœ€ä¿®æ”¹
- æ•°æ®åº“ç»“æ„æ— éœ€ä¿®æ”¹

âœ… **å‘åå…¼å®¹**ï¼š
- `WORKER_CONCURRENCY=1` æ—¶ï¼Œè¡Œä¸ºä¸å½“å‰ç‰ˆæœ¬å®Œå…¨ä¸€è‡´
- å¯ä»¥é€æ­¥å¢åŠ å¹¶å‘æ•°ï¼Œæ— éœ€åœæœº

---

## ğŸ“ å®æ–½æ­¥éª¤

### é˜¶æ®µ 1: åŸºç¡€å®ç°ï¼ˆ1-2 å¤©ï¼‰
1. ä¿®æ”¹ `worker/main.py` æ”¯æŒå¤šè¿›ç¨‹
2. ä¿®æ”¹ `worker/registry.py` æ”¯æŒå¤šå®ä¾‹æ³¨å†Œ
3. æ·»åŠ ä¿¡å·å¤„ç†å’Œè¿›ç¨‹ç›‘æ§

### é˜¶æ®µ 2: æµ‹è¯•éªŒè¯ï¼ˆ1-2 å¤©ï¼‰
1. å•å…ƒæµ‹è¯•
2. é›†æˆæµ‹è¯•
3. æ€§èƒ½æµ‹è¯•

### é˜¶æ®µ 3: æ–‡æ¡£å’Œéƒ¨ç½²ï¼ˆ1 å¤©ï¼‰
1. æ›´æ–°æ–‡æ¡£
2. æ›´æ–°é…ç½®ç¤ºä¾‹
3. éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ

---

## ğŸ¯ æ€»ç»“

**æ¨èæ–¹æ¡ˆ**ï¼šå¤šè¿›ç¨‹ Worker

**ä¼˜åŠ¿**ï¼š
- âœ… çœŸæ­£çš„å¹¶å‘æ‰§è¡Œ
- âœ… å……åˆ†åˆ©ç”¨å¤šæ ¸ CPU
- âœ… è¿›ç¨‹éš”ç¦»ï¼Œé«˜å¯é æ€§
- âœ… æ˜“äºå®ç°å’Œç»´æŠ¤
- âœ… å®Œå…¨å…¼å®¹ç°æœ‰ç³»ç»Ÿ

**å®æ–½éš¾åº¦**ï¼šä½ï¼ˆ1-2 å¤©ï¼‰

**é£é™©**ï¼šä½ï¼ˆå‘åå…¼å®¹ï¼Œå¯é€æ­¥å¯ç”¨ï¼‰

**æ¨èé…ç½®**ï¼š
- å°å‹ç³»ç»Ÿï¼š`WORKER_CONCURRENCY = 2-4`
- ä¸­å‹ç³»ç»Ÿï¼š`WORKER_CONCURRENCY = 4-8`
- å¤§å‹ç³»ç»Ÿï¼š`WORKER_CONCURRENCY = 8-16`

