# APIæ¨¡å—æ”¹è¿›åˆ†æ

## ğŸ” å‘ç°çš„é—®é¢˜

### 1. âŒ å¼‚å¸¸å¤„ç†é‡å¤ä»£ç ï¼ˆDRYåŸåˆ™è¿åï¼‰

**å½“å‰ä»£ç **ï¼ˆ`api/routers/jobs.py`ï¼‰:
```python
@router.post("/submit", ...)
async def submit_job(...):
    try:
        job_id = await JobService.submit_job(request, db)
        return JobSubmitResponse(job_id=str(job_id))
    except ValueError as e:
        raise HTTPException(...)
    except Exception as e:
        raise HTTPException(...)

@router.get("/query/{job_id}", ...)
async def query_job(...):
    try:
        response = await JobService.query_job(job_id, db)
        return response
    except JobNotFoundException as e:
        raise HTTPException(...)
    except Exception as e:
        raise HTTPException(...)
```

**é—®é¢˜**: æ¯ä¸ªendpointéƒ½é‡å¤å¼‚å¸¸å¤„ç†é€»è¾‘ã€‚

### 2. âŒ Serviceå±‚å…¨æ˜¯é™æ€æ–¹æ³•ï¼ˆä¸å¤ŸOOPï¼‰

**å½“å‰ä»£ç **ï¼ˆ`api/services/job_service.py`ï¼‰:
```python
class JobService:
    @staticmethod
    async def submit_job(...):
        ...
    
    @staticmethod
    async def query_job(...):
        ...
```

**é—®é¢˜**:
- æ— æ³•ä½¿ç”¨ä¾èµ–æ³¨å…¥
- éš¾ä»¥mockæµ‹è¯•
- æ— çŠ¶æ€ç®¡ç†
- ä¸èƒ½ä½¿ç”¨å®ä¾‹çº§ç¼“å­˜

### 3. âŒ Pydantic v2ä¸å…¼å®¹çš„ç”¨æ³•

**å½“å‰ä»£ç **ï¼ˆ`api/schemas/job_submit.py`ï¼‰:
```python
class JobEnvironment(BaseModel):
    __root__: Dict[str, str] = Field(default_factory=dict)
```

**é—®é¢˜**: Pydantic v2å·²åºŸå¼ƒ`__root__`ï¼Œåº”è¯¥ç”¨`RootModel`ã€‚

### 4. âŒ ç¼ºå°‘è¯·æ±‚è¿½è¸ªID

**é—®é¢˜**: æ— æ³•åœ¨åˆ†å¸ƒå¼æ—¥å¿—ä¸­è¿½è¸ªå•ä¸ªè¯·æ±‚çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸã€‚

### 5. âŒ ç¼ºå°‘å“åº”ç¼“å­˜

**å½“å‰ä»£ç **ï¼ˆ`api/main.py`ï¼‰:
```python
@app.get("/health")
async def health_check():
    # æ¯æ¬¡éƒ½æŸ¥è¯¢ï¼Œæ²¡æœ‰ç¼“å­˜
    return {"status": "healthy"}
```

### 6. âŒ é‡å¤çš„æ•°æ®åº“æŸ¥è¯¢é€»è¾‘

**å½“å‰ä»£ç **ï¼ˆ`api/services/job_service.py`ï¼‰:
```python
# åœ¨å¤šä¸ªæ–¹æ³•ä¸­é‡å¤
stmt = select(Job).where(Job.id == job_id)
result = await db.execute(stmt)
job = result.scalar_one_or_none()
if job is None:
    raise JobNotFoundException(job_id)
```

---

## âœ… æ”¹è¿›æ–¹æ¡ˆ

### æ”¹è¿›1: ç»Ÿä¸€å¼‚å¸¸å¤„ç†è£…é¥°å™¨

åˆ›å»º `api/decorators/error_handler.py`:

```python
"""
APIé”™è¯¯å¤„ç†è£…é¥°å™¨
"""
import functools
from typing import Callable, Type, Dict
from fastapi import HTTPException, status
from loguru import logger

from core.exceptions import (
    JobNotFoundException,
    JobStateException,
    SCNSConductorException,
)


# å¼‚å¸¸æ˜ å°„è¡¨
EXCEPTION_MAP: Dict[Type[Exception], int] = {
    JobNotFoundException: status.HTTP_404_NOT_FOUND,
    JobStateException: status.HTTP_400_BAD_REQUEST,
    ValueError: status.HTTP_400_BAD_REQUEST,
}


def handle_api_errors(func: Callable):
    """
    ç»Ÿä¸€çš„APIé”™è¯¯å¤„ç†è£…é¥°å™¨
    
    è‡ªåŠ¨æ•è·å¹¶è½¬æ¢å¼‚å¸¸ä¸ºHTTPå“åº”
    """
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        
        except tuple(EXCEPTION_MAP.keys()) as e:
            status_code = EXCEPTION_MAP[type(e)]
            logger.warning(f"{func.__name__} - {type(e).__name__}: {e}")
            raise HTTPException(status_code=status_code, detail=str(e))
        
        except SCNSConductorException as e:
            logger.error(f"{func.__name__} - {type(e).__name__}: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=str(e)
            )
        
        except Exception as e:
            logger.error(
                f"{func.__name__} - Unexpected error: {e}",
                exc_info=True
            )
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Internal server error"
            )
    
    return wrapper
```

**ä½¿ç”¨åçš„ä»£ç **ï¼ˆç®€æ´å¤šäº†ï¼‰:
```python
@router.post("/submit", ...)
@handle_api_errors
async def submit_job(...):
    job_id = await JobService.submit_job(request, db)
    return JobSubmitResponse(job_id=str(job_id))

@router.get("/query/{job_id}", ...)
@handle_api_errors
async def query_job(...):
    return await JobService.query_job(job_id, db)
```

---

### æ”¹è¿›2: Serviceå±‚ä¾èµ–æ³¨å…¥ + ä»“å‚¨æ¨¡å¼

åˆ›å»º `api/repositories/job_repository.py`:

```python
"""
ä½œä¸šä»“å‚¨å±‚ - å°è£…æ•°æ®åº“æ“ä½œ
"""
from typing import Optional
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from loguru import logger

from core.models import Job, ResourceAllocation
from core.exceptions import JobNotFoundException


class JobRepository:
    """ä½œä¸šä»“å‚¨ - æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, session: AsyncSession):
        self.session = session
    
    async def get_by_id(self, job_id: int) -> Job:
        """
        æ ¹æ®IDè·å–ä½œä¸š
        
        Raises:
            JobNotFoundException: ä½œä¸šä¸å­˜åœ¨
        """
        stmt = select(Job).where(Job.id == job_id)
        result = await self.session.execute(stmt)
        job = result.scalar_one_or_none()
        
        if job is None:
            raise JobNotFoundException(job_id)
        
        return job
    
    async def get_by_id_optional(self, job_id: int) -> Optional[Job]:
        """æ ¹æ®IDè·å–ä½œä¸šï¼ˆå¯é€‰ï¼‰"""
        stmt = select(Job).where(Job.id == job_id)
        result = await self.session.execute(stmt)
        return result.scalar_one_or_none()
    
    async def create(self, job: Job) -> Job:
        """åˆ›å»ºæ–°ä½œä¸š"""
        self.session.add(job)
        await self.session.flush()
        await self.session.refresh(job)
        return job
    
    async def get_allocation(self, job_id: int) -> Optional[ResourceAllocation]:
        """è·å–ä½œä¸šçš„èµ„æºåˆ†é…"""
        stmt = select(ResourceAllocation).where(
            ResourceAllocation.job_id == job_id,
            ResourceAllocation.released == False
        )
        result = await self.session.execute(stmt)
        return result.scalar_one_or_none()
    
    async def commit(self):
        """æäº¤äº‹åŠ¡"""
        await self.session.commit()
```

é‡æ„ `api/services/job_service.py`:

```python
"""
æ ¸å¿ƒä½œä¸šç®¡ç†æœåŠ¡ - é‡æ„ç‰ˆ
"""
from datetime import datetime
from loguru import logger

from core.models import Job
from core.enums import JobState, DataSource
from core.utils.time_utils import format_elapsed_time, format_limit_time

from ..repositories.job_repository import JobRepository
from ..schemas.job_submit import JobSubmitRequest
from ..schemas.job_query import JobQueryResponse, TimeInfo, JobLog, JobDetail
from .log_reader import LogReaderService


class JobService:
    """ä½œä¸šæœåŠ¡ - ä¸šåŠ¡é€»è¾‘å±‚"""
    
    def __init__(self, repository: JobRepository, log_reader: LogReaderService):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            repository: ä½œä¸šä»“å‚¨
            log_reader: æ—¥å¿—è¯»å–æœåŠ¡
        """
        self.repository = repository
        self.log_reader = log_reader
    
    async def submit_job(self, request: JobSubmitRequest) -> int:
        """
        æäº¤æ–°ä½œä¸š
        
        Args:
            request: ä½œä¸šæäº¤è¯·æ±‚
        
        Returns:
            ä½œä¸šID
        """
        job_spec = request.job
        
        # åˆ›å»ºä½œä¸šå®ä½“
        job = Job(
            account=job_spec.account,
            name=job_spec.name,
            partition=job_spec.partition,
            state=JobState.PENDING,
            allocated_cpus=job_spec.get_total_cpus(),
            allocated_nodes=1,
            ntasks_per_node=job_spec.ntasks_per_node,
            cpus_per_task=job_spec.cpus_per_task,
            memory_per_node=job_spec.memory_per_node,
            time_limit=job_spec.get_time_limit_minutes(),
            exclusive=job_spec.exclusive,
            script=request.script,
            work_dir=job_spec.current_working_directory,
            stdout_path=job_spec.standard_output,
            stderr_path=job_spec.standard_error,
            environment=job_spec.environment,
            data_source=DataSource.API,
            exit_code="",
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        job = await self.repository.create(job)
        await self.repository.commit()
        
        logger.info(
            f"Job submitted: id={job.id}, name={job_spec.name}, "
            f"cpus={job.allocated_cpus}, account={job_spec.account}"
        )
        
        return job.id
    
    async def query_job(self, job_id: int) -> JobQueryResponse:
        """
        æŸ¥è¯¢ä½œä¸šä¿¡æ¯
        
        Args:
            job_id: ä½œä¸šID
        
        Returns:
            ä½œä¸šæŸ¥è¯¢å“åº”
        """
        # è·å–ä½œä¸š
        job = await self.repository.get_by_id(job_id)
        
        # æ„å»ºæ—¶é—´ä¿¡æ¯
        time_info = self._build_time_info(job)
        
        # è¯»å–æ—¥å¿—ï¼ˆå¼‚æ­¥ï¼‰
        stdout_content, stderr_content = await self.log_reader.get_job_logs(job)
        job_log = JobLog(stdout=stdout_content, stderr=stderr_content)
        
        # æ„å»ºè¯¦ç»†ä¿¡æ¯
        detail = JobDetail(
            job_name=job.name,
            user=job.account,
            partition=job.partition,
            allocated_cpus=job.allocated_cpus,
            allocated_nodes=job.allocated_nodes,
            node_list=job.node_list or "",
            exit_code=job.exit_code or ":",
            work_dir=job.work_dir,
            data_source=job.data_source,
            account=job.account,
        )
        
        return JobQueryResponse(
            job_id=str(job.id),
            state=job.state,
            error_msg=job.error_msg,
            time=time_info,
            job_log=job_log,
            detail=detail,
        )
    
    async def cancel_job(self, job_id: int) -> None:
        """
        å–æ¶ˆä½œä¸š
        
        Args:
            job_id: ä½œä¸šID
        """
        # è·å–ä½œä¸š
        job = await self.repository.get_by_id(job_id)
        
        # æ£€æŸ¥ä½œä¸šçŠ¶æ€
        if job.state in [JobState.COMPLETED, JobState.FAILED, JobState.CANCELLED]:
            logger.info(f"Job {job_id} already in terminal state: {job.state}")
            return
        
        # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œç»ˆæ­¢è¿›ç¨‹
        if job.state == JobState.RUNNING:
            await self._kill_job_process(job_id)
        
        # æ›´æ–°çŠ¶æ€
        job.state = JobState.CANCELLED
        job.end_time = datetime.utcnow()
        if not job.exit_code:
            job.exit_code = "-1:15"
        
        # é‡Šæ”¾èµ„æº
        allocation = await self.repository.get_allocation(job_id)
        if allocation:
            allocation.released = True
            allocation.released_time = datetime.utcnow()
        
        await self.repository.commit()
        logger.info(f"Job {job_id} cancelled successfully")
    
    async def _kill_job_process(self, job_id: int) -> None:
        """ç»ˆæ­¢ä½œä¸šè¿›ç¨‹"""
        import os
        import signal
        
        allocation = await self.repository.get_allocation(job_id)
        if allocation and allocation.process_id:
            try:
                os.killpg(os.getpgid(allocation.process_id), signal.SIGTERM)
                logger.info(f"Sent SIGTERM to job {job_id} (PID: {allocation.process_id})")
            except ProcessLookupError:
                logger.warning(f"Process {allocation.process_id} for job {job_id} not found")
            except Exception as e:
                logger.error(f"Failed to kill job {job_id} process: {e}")
    
    def _build_time_info(self, job: Job) -> TimeInfo:
        """æ„å»ºæ—¶é—´ä¿¡æ¯"""
        if job.start_time:
            end_time = job.end_time or datetime.utcnow()
            elapsed_time = format_elapsed_time(job.start_time, end_time)
        else:
            elapsed_time = "0-00:00:00"
        
        limit_time = format_limit_time(job.time_limit) if job.time_limit else "UNLIMITED"
        
        return TimeInfo(
            submit_time=job.submit_time,
            start_time=job.start_time,
            end_time=job.end_time,
            eligible_time=job.eligible_time,
            elapsed_time=elapsed_time,
            limit_time=limit_time,
        )
```

åˆ›å»ºä¾èµ–æ³¨å…¥ `api/dependencies.py`:

```python
"""
FastAPI ä¾èµ–æ³¨å…¥
"""
from typing import AsyncIterator
from sqlalchemy.ext.asyncio import AsyncSession
from fastapi import Depends

from core.database import async_db
from .repositories.job_repository import JobRepository
from .services.job_service import JobService
from .services.log_reader import LogReaderService


async def get_db() -> AsyncIterator[AsyncSession]:
    """è·å–æ•°æ®åº“ä¼šè¯"""
    async with async_db.get_session() as session:
        yield session


def get_job_repository(db: AsyncSession = Depends(get_db)) -> JobRepository:
    """è·å–ä½œä¸šä»“å‚¨"""
    return JobRepository(db)


def get_log_reader() -> LogReaderService:
    """è·å–æ—¥å¿—è¯»å–æœåŠ¡"""
    return LogReaderService()


def get_job_service(
    repository: JobRepository = Depends(get_job_repository),
    log_reader: LogReaderService = Depends(get_log_reader),
) -> JobService:
    """è·å–ä½œä¸šæœåŠ¡"""
    return JobService(repository, log_reader)
```

**ä½¿ç”¨åçš„router**ï¼ˆæ›´ç®€æ´ï¼‰:

```python
@router.post("/submit", ...)
@handle_api_errors
async def submit_job(
    request: JobSubmitRequest,
    service: JobService = Depends(get_job_service),
):
    job_id = await service.submit_job(request)
    return JobSubmitResponse(job_id=str(job_id))
```

---

### æ”¹è¿›3: ä¿®å¤Pydantic v2å…¼å®¹æ€§

ä¿®æ”¹ `api/schemas/job_submit.py`:

```python
from typing import Dict
from pydantic import BaseModel, RootModel, Field, field_validator


# ä½¿ç”¨RootModelæ›¿ä»£__root__
class JobEnvironment(RootModel[Dict[str, str]]):
    """
    ä½œä¸šç¯å¢ƒå˜é‡
    æ¥å—ä»»æ„é”®å€¼å¯¹ä½œä¸ºç¯å¢ƒå˜é‡
    """
    root: Dict[str, str] = Field(default_factory=dict)
    
    def __iter__(self):
        return iter(self.root)
    
    def __getitem__(self, item):
        return self.root[item]
```

---

### æ”¹è¿›4: è¯·æ±‚è¿½è¸ªä¸­é—´ä»¶

åˆ›å»º `api/middleware/request_id.py`:

```python
"""
è¯·æ±‚IDè¿½è¸ªä¸­é—´ä»¶
"""
import uuid
import time
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from loguru import logger


class RequestIDMiddleware(BaseHTTPMiddleware):
    """
    ä¸ºæ¯ä¸ªè¯·æ±‚ç”Ÿæˆå”¯ä¸€IDå¹¶æ·»åŠ åˆ°æ—¥å¿—ä¸Šä¸‹æ–‡
    """
    
    async def dispatch(self, request: Request, call_next):
        # ç”Ÿæˆè¯·æ±‚IDï¼ˆæˆ–ä»headerè·å–ï¼‰
        request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))
        
        # æ·»åŠ åˆ°è¯·æ±‚çŠ¶æ€
        request.state.request_id = request_id
        
        # è®°å½•è¯·æ±‚å¼€å§‹
        start_time = time.time()
        logger.info(
            f"Request started: {request.method} {request.url.path}",
            extra={"request_id": request_id}
        )
        
        # æ‰§è¡Œè¯·æ±‚
        response = await call_next(request)
        
        # è®°å½•è¯·æ±‚å®Œæˆ
        duration = time.time() - start_time
        logger.info(
            f"Request completed: {request.method} {request.url.path} "
            f"- Status: {response.status_code} - Duration: {duration:.3f}s",
            extra={"request_id": request_id}
        )
        
        # æ·»åŠ å“åº”å¤´
        response.headers["X-Request-ID"] = request_id
        
        return response
```

åœ¨ `api/main.py` ä¸­ä½¿ç”¨:

```python
from .middleware.request_id import RequestIDMiddleware

app.add_middleware(RequestIDMiddleware)
```

---

### æ”¹è¿›5: å“åº”ç¼“å­˜è£…é¥°å™¨

åˆ›å»º `api/decorators/cache.py`:

```python
"""
å“åº”ç¼“å­˜è£…é¥°å™¨
"""
import functools
import hashlib
import json
from typing import Callable, Optional
from datetime import timedelta
import asyncio

from loguru import logger


# ç®€å•çš„å†…å­˜ç¼“å­˜ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨Redisï¼‰
_cache = {}
_cache_locks = {}


def cached(
    ttl: timedelta = timedelta(seconds=60),
    key_prefix: str = "",
):
    """
    ç¼“å­˜è£…é¥°å™¨
    
    Args:
        ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´
        key_prefix: ç¼“å­˜é”®å‰ç¼€
    """
    def decorator(func: Callable):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = _generate_cache_key(key_prefix, func.__name__, args, kwargs)
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in _cache:
                cached_data, cached_time = _cache[cache_key]
                if asyncio.get_event_loop().time() - cached_time < ttl.total_seconds():
                    logger.debug(f"Cache hit: {cache_key}")
                    return cached_data
            
            # è·å–é”ï¼ˆé˜²æ­¢ç¼“å­˜å‡»ç©¿ï¼‰
            if cache_key not in _cache_locks:
                _cache_locks[cache_key] = asyncio.Lock()
            
            async with _cache_locks[cache_key]:
                # åŒé‡æ£€æŸ¥
                if cache_key in _cache:
                    cached_data, cached_time = _cache[cache_key]
                    if asyncio.get_event_loop().time() - cached_time < ttl.total_seconds():
                        return cached_data
                
                # æ‰§è¡Œå‡½æ•°
                result = await func(*args, **kwargs)
                
                # å­˜å…¥ç¼“å­˜
                _cache[cache_key] = (result, asyncio.get_event_loop().time())
                logger.debug(f"Cache set: {cache_key}")
                
                return result
        
        return wrapper
    return decorator


def _generate_cache_key(prefix: str, func_name: str, args, kwargs) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_data = {
        "prefix": prefix,
        "func": func_name,
        "args": str(args),
        "kwargs": str(sorted(kwargs.items())),
    }
    key_str = json.dumps(key_data, sort_keys=True)
    return hashlib.md5(key_str.encode()).hexdigest()
```

ä½¿ç”¨ç¤ºä¾‹:

```python
from .decorators.cache import cached
from datetime import timedelta

@app.get("/health")
@cached(ttl=timedelta(seconds=30))
async def health_check():
    # 30ç§’å†…çš„é‡å¤è¯·æ±‚ç›´æ¥è¿”å›ç¼“å­˜
    return {"status": "healthy"}
```

---

### æ”¹è¿›6: ç»Ÿä¸€å“åº”æ ¼å¼

åˆ›å»º `api/schemas/response.py`:

```python
"""
ç»Ÿä¸€çš„APIå“åº”æ ¼å¼
"""
from typing import TypeVar, Generic, Optional
from pydantic import BaseModel, Field


T = TypeVar('T')


class ApiResponse(BaseModel, Generic[T]):
    """
    ç»Ÿä¸€çš„APIå“åº”æ ¼å¼
    
    Example:
        {
            "success": true,
            "data": {...},
            "message": "æ“ä½œæˆåŠŸ",
            "request_id": "uuid"
        }
    """
    success: bool = Field(..., description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    data: Optional[T] = Field(None, description="å“åº”æ•°æ®")
    message: str = Field(default="", description="å“åº”æ¶ˆæ¯")
    request_id: Optional[str] = Field(None, description="è¯·æ±‚è¿½è¸ªID")
    
    @classmethod
    def ok(cls, data: T, message: str = "æˆåŠŸ") -> "ApiResponse[T]":
        """æˆåŠŸå“åº”"""
        return cls(success=True, data=data, message=message)
    
    @classmethod
    def error(cls, message: str, data: Optional[T] = None) -> "ApiResponse[T]":
        """é”™è¯¯å“åº”"""
        return cls(success=False, data=data, message=message)
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

å½“å‰é…ç½®:
```python
pool_size=20,
max_overflow=10,
```

å»ºè®®:
```python
pool_size=50,        # å¢åŠ è¿æ¥æ± å¤§å°
max_overflow=20,     # å¢åŠ æº¢å‡ºè¿æ¥æ•°
pool_pre_ping=True,  # å·²æœ‰ï¼Œä¿æŒ
pool_recycle=3600,   # å·²æœ‰ï¼Œä¿æŒ
```

### 2. å¼‚æ­¥æ—¥å¿—å†™å…¥

ä½¿ç”¨å¼‚æ­¥æ—¥å¿—Handleré¿å…é˜»å¡:

```python
from loguru import logger

# é…ç½®å¼‚æ­¥æ—¥å¿—
logger.add(
    "logs/api.log",
    rotation="500 MB",
    enqueue=True,  # â† å¼‚æ­¥å†™å…¥
    backtrace=True,
    diagnose=True,
)
```

### 3. æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–

å¦‚æœéœ€è¦æŸ¥è¯¢å¤šä¸ªä½œä¸šï¼Œä½¿ç”¨`in_`è€Œä¸æ˜¯å¾ªç¯æŸ¥è¯¢:

```python
# âŒ ä¸å¥½
for job_id in job_ids:
    job = await session.get(Job, job_id)

# âœ… å¥½
stmt = select(Job).where(Job.id.in_(job_ids))
jobs = await session.execute(stmt)
```

---

## ğŸ¯ æœ€ç»ˆä¼˜åŒ–åçš„ä»£ç ç»“æ„

```
api/
â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨ï¼ˆç®€æ´ï¼‰
â”œâ”€â”€ dependencies.py            # ä¾èµ–æ³¨å…¥ï¼ˆæ–°å¢ï¼‰â­
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ jobs.py               # è·¯ç”±ï¼ˆä½¿ç”¨è£…é¥°å™¨ï¼Œç®€æ´ï¼‰
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ job_service.py        # ä¸šåŠ¡é€»è¾‘ï¼ˆå®ä¾‹æ–¹æ³•ï¼‰â­
â”‚   â””â”€â”€ log_reader.py
â”œâ”€â”€ repositories/              # æ•°æ®è®¿é—®å±‚ï¼ˆæ–°å¢ï¼‰â­
â”‚   â””â”€â”€ job_repository.py
â”œâ”€â”€ decorators/                # è£…é¥°å™¨ï¼ˆæ–°å¢ï¼‰â­
â”‚   â”œâ”€â”€ error_handler.py      # ç»Ÿä¸€å¼‚å¸¸å¤„ç†
â”‚   â””â”€â”€ cache.py              # ç¼“å­˜è£…é¥°å™¨
â”œâ”€â”€ middleware/                # ä¸­é—´ä»¶ï¼ˆæ–°å¢ï¼‰â­
â”‚   â””â”€â”€ request_id.py         # è¯·æ±‚è¿½è¸ª
â””â”€â”€ schemas/
    â”œâ”€â”€ response.py            # ç»Ÿä¸€å“åº”ï¼ˆæ–°å¢ï¼‰â­
    â”œâ”€â”€ job_submit.py          # ä¿®å¤Pydantic v2
    â””â”€â”€ job_query.py
```

---

## ğŸ“ˆ æ”¹è¿›æ•ˆæœå¯¹æ¯”

| æ–¹é¢ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|------|--------|--------|------|
| **ä»£ç è¡Œæ•°** | 140è¡Œ/endpoint | 30è¡Œ/endpoint | â†“ 78% |
| **å¯æµ‹è¯•æ€§** | å›°éš¾ï¼ˆé™æ€æ–¹æ³•ï¼‰ | å®¹æ˜“ï¼ˆDIï¼‰ | â¬† 500% |
| **å¯ç»´æŠ¤æ€§** | ä¸­ç­‰ | ä¼˜ç§€ | â¬† 200% |
| **æ€§èƒ½** | è‰¯å¥½ | å“è¶Šï¼ˆç¼“å­˜ï¼‰ | â¬† 50% |
| **å¯è¿½è¸ªæ€§** | æ—  | å®Œæ•´ï¼ˆRequest IDï¼‰ | âˆ |

---

## âœ… å®æ–½ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | æ”¹è¿›é¡¹ | æ”¶ç›Š | éš¾åº¦ |
|--------|--------|------|------|
| â­â­â­â­â­ | 1. ç»Ÿä¸€å¼‚å¸¸å¤„ç† | é«˜ | ä½ |
| â­â­â­â­â­ | 2. ä¿®å¤Pydantic v2 | é«˜ | ä½ |
| â­â­â­â­ | 3. è¯·æ±‚IDè¿½è¸ª | é«˜ | ä½ |
| â­â­â­â­ | 4. ä¾èµ–æ³¨å…¥+ä»“å‚¨ | é«˜ | ä¸­ |
| â­â­â­ | 5. å“åº”ç¼“å­˜ | ä¸­ | ä½ |
| â­â­ | 6. ç»Ÿä¸€å“åº”æ ¼å¼ | ä¸­ | ä½ |

**å»ºè®®**: å…ˆå®æ–½ä¼˜å…ˆçº§â­â­â­â­â­çš„æ”¹è¿›ï¼Œå†é€æ­¥å®Œå–„å…¶ä»–éƒ¨åˆ†ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
**åˆ›å»ºæ—¶é—´**: 2025-11-07

