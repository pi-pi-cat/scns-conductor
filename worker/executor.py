"""
Job Executor - ‰Ωú‰∏öÊâßË°åÂô®

Ë¥üË¥£ÊâßË°å‰Ωú‰∏öËÑöÊú¨Âπ∂ÁÆ°ÁêÜ‰Ωú‰∏öÁîüÂëΩÂë®Êúü
"""

import os
import subprocess
from pathlib import Path
from typing import Optional

from loguru import logger

from core.config import get_settings
from core.database import sync_db
from core.models import Job
from core.enums import JobState, ResourceStatus
from core.services import ResourceManager

from worker.execution import JobExecutionContext, ExecutionStage
from worker.middleware import MiddlewareManager, create_default_manager
from worker.monitoring import ProcessMonitor
from worker.process import store_pid, kill_process_tree
from worker.repositories import WorkerRepository
from worker.resources import ResourceManagerWrapper


class JobExecutor:
    """
    ‰Ωú‰∏öÊâßË°åÂô®

    Êû∂ÊûÑËØ¥ÊòéÔºö
    - ‰ΩøÁî® JobExecutionContext Áªü‰∏ÄÁÆ°ÁêÜÊâßË°åÁä∂ÊÄÅ
    - ‰ΩøÁî® ResourceManagerWrapper Á°Æ‰øùËµÑÊ∫êÊ≠£Á°ÆÈáäÊîæ
    - ‰ΩøÁî® ExecutionStage ÂàíÂàÜÊâßË°åÈò∂ÊÆµ
    - ‰ΩøÁî® ExecutionMiddleware Êèê‰æõÂèØÊâ©Â±ïÁöÑÂ§ÑÁêÜÊú∫Âà∂
    - ‰ΩøÁî® ProcessMonitor ÁõëÊéßËøõÁ®ãÁä∂ÊÄÅ
    - ‰ΩøÁî® WorkerRepository Â∞ÅË£ÖÊï∞ÊçÆÂ∫ìÊìç‰Ωú
    - ÈÅµÂæ™Âçï‰∏ÄËÅåË¥£ÂéüÂàôÂíåÂÖ≥Ê≥®ÁÇπÂàÜÁ¶ª
    - ÊîØÊåÅ‰æùËµñÊ≥®ÂÖ•Ôºå‰æø‰∫éÊµãËØï
    """

    def __init__(
        self,
        resource_manager: Optional[ResourceManager] = None,
        middleware_manager: Optional[MiddlewareManager] = None,
        process_monitor: Optional[ProcessMonitor] = None,
        worker_repository: Optional[WorkerRepository] = None,
        settings=None,
    ):
        """
        ÂàùÂßãÂåñÊâßË°åÂô®

        Args:
            resource_manager: ËµÑÊ∫êÁÆ°ÁêÜÂô®ÔºàÂèØÈÄâÔºåÁî®‰∫é‰æùËµñÊ≥®ÂÖ•Ôºâ
            middleware_manager: ‰∏≠Èó¥‰ª∂ÁÆ°ÁêÜÂô®ÔºàÂèØÈÄâÔºåÁî®‰∫é‰æùËµñÊ≥®ÂÖ•Ôºâ
            process_monitor: ËøõÁ®ãÁõëÊéßÂô®ÔºàÂèØÈÄâÔºåÁî®‰∫é‰æùËµñÊ≥®ÂÖ•Ôºâ
            worker_repository: Worker ‰ªìÂÇ®ÔºàÂèØÈÄâÔºåÁî®‰∫é‰æùËµñÊ≥®ÂÖ•Ôºâ
            settings: ÈÖçÁΩÆÂØπË±°ÔºàÂèØÈÄâÔºåÁî®‰∫é‰æùËµñÊ≥®ÂÖ•Ôºâ
        """
        self.settings = settings or get_settings()
        base_resource_manager = resource_manager or ResourceManager()
        self.resource_wrapper = ResourceManagerWrapper(base_resource_manager)
        self.middleware_manager = middleware_manager or create_default_manager()
        self.process_monitor = process_monitor or ProcessMonitor()
        self.worker_repository = worker_repository or WorkerRepository

    def execute(self, job_id: int):
        """
        ÊâßË°å‰Ωú‰∏ö

        ‰ΩøÁî®ÊâßË°å‰∏ä‰∏ãÊñáÁªü‰∏ÄÁÆ°ÁêÜÁä∂ÊÄÅÔºå‰ΩøÁî®ËµÑÊ∫êÁÆ°ÁêÜÂô®ÂåÖË£ÖÂô®Á°Æ‰øùËµÑÊ∫êÊ≠£Á°ÆÈáäÊîæ„ÄÇ
        ÊîØÊåÅÊâßË°åÈò∂ÊÆµÂíå‰∏≠Èó¥‰ª∂Êú∫Âà∂„ÄÇ

        Args:
            job_id: ‰Ωú‰∏ö ID
        """
        logger.info(f"üöÄ Executing job {job_id}")

        # ÂàõÂª∫ÊâßË°å‰∏ä‰∏ãÊñá
        context = JobExecutionContext(job_id=job_id)

        # Èò∂ÊÆµ 1: ÂàùÂßãÂåñ
        self._on_stage(ExecutionStage.INITIALIZED, context)

        # ÊâßË°åÂâç‰∏≠Èó¥‰ª∂
        context = self.middleware_manager.execute_before(context)

        try:
            # Èò∂ÊÆµ 2: Âä†ËΩΩ‰Ωú‰∏ö
            context.job = self._load_job(job_id)
            self._on_stage(ExecutionStage.LOADED, context)

            # È™åËØÅÁä∂ÊÄÅ
            if context.job.state != JobState.RUNNING:
                logger.error(
                    f"Job {job_id} state is {context.job.state.value}, expected RUNNING"
                )
                return

            # Èò∂ÊÆµ 3: ËµÑÊ∫êÂàÜÈÖç
            # ÈáçË¶ÅÔºöÂú®ÁúüÊ≠£ÂºÄÂßãÊâßË°åÂâçÔºåÂ∞ÜËµÑÊ∫êÁä∂ÊÄÅ‰ªé reserved Êõ¥Êñ∞‰∏∫ allocated
            self._mark_resources_allocated(job_id, context.job.allocated_cpus)
            self._on_stage(ExecutionStage.RESOURCES_ALLOCATED, context)

            # Èò∂ÊÆµ 4: ÁéØÂ¢ÉÂáÜÂ§á
            self._prepare_environment(context)
            self._on_stage(ExecutionStage.PREPARED, context)

            # ‰ΩøÁî®ËµÑÊ∫êÁÆ°ÁêÜÂô®ÂåÖË£ÖÂô®Á°Æ‰øùËµÑÊ∫êÊ≠£Á°ÆÈáäÊîæ
            with self.resource_wrapper.allocate_for_job(
                job_id, context.job.allocated_cpus
            ):
                # Èò∂ÊÆµ 5: ÊâßË°å‰Ωú‰∏ö
                self._on_stage(ExecutionStage.RUNNING, context)
                context.exit_code = self._run(context)

                # Èò∂ÊÆµ 6: ÊâßË°åÂÆåÊàê
                self._on_stage(ExecutionStage.COMPLETED, context)

        except Exception as e:
            logger.error(f"‚ùå Job {job_id} failed: {e}", exc_info=True)
            context.error = e
            self._on_stage(ExecutionStage.FAILED, context)

            # ÈîôËØØÂ§ÑÁêÜ‰∏≠Èó¥‰ª∂
            self.middleware_manager.execute_on_error(context, e)

        finally:
            # Èò∂ÊÆµ 7: Ê∏ÖÁêÜ
            self._cleanup(context)
            self._on_stage(ExecutionStage.CLEANED_UP, context)

            # ÊâßË°åÂêé‰∏≠Èó¥‰ª∂
            context = self.middleware_manager.execute_after(context)

            logger.info(
                f"‚úÖ Job {job_id} finished (elapsed: {context.elapsed_time():.2f}s)"
            )

    def _on_stage(self, stage: ExecutionStage, context: JobExecutionContext):
        """
        Èò∂ÊÆµÈí©Â≠êÊñπÊ≥ï

        ÂèØ‰ª•Ë¢´Â≠êÁ±ªÈáçÂÜôÊàñÈÄöËøá‰∏≠Èó¥‰ª∂Êâ©Â±ï

        Args:
            stage: ÊâßË°åÈò∂ÊÆµ
            context: ÊâßË°å‰∏ä‰∏ãÊñá
        """
        logger.debug(f"Job {context.job_id} entered stage: {stage.value}")

        # Ë∞ÉÁî®‰∏≠Èó¥‰ª∂ÁöÑÈò∂ÊÆµÈí©Â≠ê
        context = self.middleware_manager.execute_on_stage(stage.value, context)

    def _load_job(self, job_id: int) -> Job:
        """Âä†ËΩΩ‰Ωú‰∏ö‰ø°ÊÅØ"""
        with sync_db.get_session() as session:
            job = self.worker_repository.get_job_by_id(session, job_id)
            if not job:
                raise ValueError(f"Job {job_id} not found")
            return job

    def _prepare_environment(self, context: JobExecutionContext):
        """
        ÂáÜÂ§áÊâßË°åÁéØÂ¢É

        Args:
            context: ÊâßË°å‰∏ä‰∏ãÊñá
        """
        job = context.job
        context.script_path = self._prepare_script(job)
        context.stdout_path = Path(job.work_dir) / job.stdout_path
        context.stderr_path = Path(job.work_dir) / job.stderr_path

        # ÂáÜÂ§áÁéØÂ¢ÉÂèòÈáè
        context.env = os.environ.copy()
        if job.environment:
            context.env.update(job.environment)

    def _run(self, context: JobExecutionContext) -> int:
        """
        ËøêË°å‰Ωú‰∏öËÑöÊú¨

        Args:
            context: ÊâßË°å‰∏ä‰∏ãÊñá

        Returns:
            ÈÄÄÂá∫Á†Å
        """
        job = context.job
        logger.info(f"Running job {job.id}: {job.name}")

        # ÊâßË°åËÑöÊú¨
        try:
            with (
                open(context.stdout_path, "w") as stdout,
                open(context.stderr_path, "w") as stderr,
            ):
                context.process = subprocess.Popen(
                    ["/bin/bash", context.script_path],
                    stdout=stdout,
                    stderr=stderr,
                    cwd=job.work_dir,
                    env=context.env,
                    preexec_fn=os.setsid,
                )

                # ËÆ∞ÂΩïËøõÁ®ã‰ø°ÊÅØ
                context.process_id = context.process.pid
                store_pid(job.id, context.process_id)
                logger.info(f"Job {job.id} started, PID: {context.process_id}")

                # ÂºÄÂßãÁõëÊéßËøõÁ®ã
                self.process_monitor.start_monitoring(job.id, context)

                # Á≠âÂæÖÂÆåÊàêÔºàÊîØÊåÅË∂ÖÊó∂Ôºâ
                try:
                    timeout = job.time_limit * 60 if job.time_limit else None
                    exit_code = context.process.wait(timeout=timeout)
                except subprocess.TimeoutExpired:
                    logger.warning(f"Job {job.id} timeout, terminating...")
                    kill_process_tree(context.process_id, timeout=5)
                    exit_code = -1
                finally:
                    # ÂÅúÊ≠¢ÁõëÊéßËøõÁ®ã
                    self.process_monitor.stop_monitoring(job.id)

                logger.info(f"Job {job.id} finished, exit code: {exit_code}")
                return exit_code

        except Exception as e:
            logger.error(f"Failed to run job {job.id}: {e}")
            # Á°Æ‰øùÂÅúÊ≠¢ÁõëÊéß
            self.process_monitor.stop_monitoring(job.id)
            raise

    def _prepare_script(self, job: Job) -> str:
        """ÂáÜÂ§áËÑöÊú¨Êñá‰ª∂"""
        # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
        Path(job.work_dir).mkdir(parents=True, exist_ok=True)

        # ÂÜôÂÖ•ËÑöÊú¨
        script_path = Path(self.settings.SCRIPT_DIR) / f"job_{job.id}.sh"
        script_path.parent.mkdir(parents=True, exist_ok=True)

        script_path.write_text(job.script)
        script_path.chmod(0o755)

        return str(script_path)

    def _cleanup(self, context: JobExecutionContext):
        """
        Ê∏ÖÁêÜËµÑÊ∫ê

        Args:
            context: ÊâßË°å‰∏ä‰∏ãÊñá
        """
        # ÈáäÊîæÊï∞ÊçÆÂ∫ì‰∏≠ÁöÑËµÑÊ∫êÂàÜÈÖçÔºàÊõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ releasedÔºâ
        self._release_resources(context.job_id)

        # Êõ¥Êñ∞ÊúÄÁªàÁä∂ÊÄÅ
        if context.has_error():
            self._mark_failed(context.job_id, str(context.error))
        elif context.exit_code is not None:
            self._update_completion(context.job_id, context.exit_code)

    def _update_completion(self, job_id: int, exit_code: int):
        """Êõ¥Êñ∞‰Ωú‰∏öÂÆåÊàêÁä∂ÊÄÅ"""
        with sync_db.get_session() as session:
            if self.worker_repository.update_job_completion(session, job_id, exit_code):
                session.commit()
                state = JobState.COMPLETED if exit_code == 0 else JobState.FAILED
                logger.info(f"Job {job_id} marked as {state.value}")

    def _mark_failed(self, job_id: int, error_msg: str):
        """Ê†áËÆ∞‰Ωú‰∏öÂ§±Ë¥•"""
        try:
            with sync_db.get_session() as session:
                if self.worker_repository.update_job_failed(session, job_id, error_msg):
                    session.commit()
        except Exception as e:
            logger.error(f"Failed to mark job {job_id} as failed: {e}")

    def _mark_resources_allocated(self, job_id: int, cpus: int):
        """
        Â∞ÜËµÑÊ∫êÁä∂ÊÄÅ‰ªé reserved Êõ¥Êñ∞‰∏∫ allocated

        ËøôÊòØËµÑÊ∫êÁúüÊ≠£Ë¢´Âç†Áî®ÁöÑÊó∂ÂàªÔºåÂè™ÊúâÂú® Worker ÁúüÊ≠£ÂºÄÂßãÊâßË°å‰Ωú‰∏öÊó∂ÊâçË∞ÉÁî®„ÄÇ
        ËøôÊ†∑ÂèØ‰ª•ÈÅøÂÖç‰Ωú‰∏öË¢´Ë∞ÉÂ∫¶‰ΩÜÊú™ÂÆûÈôÖËøêË°åÂØºËá¥ÁöÑËµÑÊ∫êÊ≥ÑÊºèÈóÆÈ¢ò„ÄÇ

        Args:
            job_id: ‰Ωú‰∏ö ID
            cpus: CPU Êï∞Èáè
        """
        with sync_db.get_session() as session:
            allocation = self.worker_repository.update_allocation_to_allocated(
                session, job_id
            )

            if allocation:
                session.commit()

                # Ê≥®ÊÑèÔºöËµÑÊ∫êÁÆ°ÁêÜÁî± ResourceManagerWrapper Ë¥üË¥£
                # ËøôÈáåÂè™Êõ¥Êñ∞Êï∞ÊçÆÂ∫ìÁä∂ÊÄÅÔºåÁºìÂ≠òÊõ¥Êñ∞Áî±ÂåÖË£ÖÂô®Â§ÑÁêÜ

                logger.info(
                    f"‚úÖ Resources allocated for job {job_id}: {cpus} CPUs "
                    f"(status: reserved -> allocated)"
                )
            else:
                logger.warning(
                    f"‚ö†Ô∏è  No resource allocation found for job {job_id}, "
                    f"creating new allocation"
                )
                # Â¶ÇÊûúÊ≤°ÊúâÈ¢ÑÁïôËÆ∞ÂΩïÔºàÂºÇÂ∏∏ÊÉÖÂÜµÔºâÔºåÁõ¥Êé•ÂàõÂª∫ allocated ËÆ∞ÂΩï
                self.worker_repository.create_allocation_as_allocated(
                    session=session,
                    job_id=job_id,
                    allocated_cpus=cpus,
                    node_name=self.settings.NODE_NAME,
                )
                session.commit()
                # Ê≥®ÊÑèÔºöËµÑÊ∫êÁÆ°ÁêÜÁî± ResourceManagerWrapper Ë¥üË¥£
                # ËøôÈáåÂè™Êõ¥Êñ∞Êï∞ÊçÆÂ∫ìÁä∂ÊÄÅÔºåÁºìÂ≠òÊõ¥Êñ∞Áî±ÂåÖË£ÖÂô®Â§ÑÁêÜ

    def _release_resources(self, job_id: int):
        """
        ÈáäÊîæËµÑÊ∫êÔºàÊõ¥Êñ∞Êï∞ÊçÆÂ∫ì + Redis ÁºìÂ≠òÔºâ

        Êõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ releasedÔºåÂπ∂ÂõûÊî∂ËµÑÊ∫êÂà∞ÂèØÁî®Ê±†

        Args:
            job_id: ‰Ωú‰∏ö ID
        """
        with sync_db.get_session() as session:
            result = self.worker_repository.release_allocation(session, job_id)

            if result:
                allocation, old_status = result
                cpus = allocation.allocated_cpus

                session.commit()

                # Ê≥®ÊÑèÔºöRedis ÁºìÂ≠òÁöÑÈáäÊîæÁî± ResourceManagerWrapper Ë¥üË¥£
                # ËøôÈáåÂè™Êõ¥Êñ∞Êï∞ÊçÆÂ∫ìÁä∂ÊÄÅ
                if old_status == ResourceStatus.ALLOCATED:
                    logger.info(
                        f"‚ôªÔ∏è  Released {cpus} CPUs for job {job_id} "
                        f"(status: allocated -> released)"
                    )
                else:
                    logger.info(
                        f"‚ôªÔ∏è  Released reservation for job {job_id} "
                        f"(status: {old_status} -> released)"
                    )
            else:
                logger.warning(f"‚ö†Ô∏è  No unreleased allocation found for job {job_id}")


# RQ ‰ªªÂä°ÂÖ•Âè£
def execute_job(job_id: int):
    """
    RQ ‰ªªÂä°ÂáΩÊï∞

    Args:
        job_id: ‰Ωú‰∏ö ID
    """
    executor = JobExecutor()
    executor.execute(job_id)
