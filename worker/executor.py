"""
Job Executor - ‰Ωú‰∏öÊâßË°åÂô®

Ë¥üË¥£ÊâßË°å‰Ωú‰∏öËÑöÊú¨Âπ∂ÁÆ°ÁêÜ‰Ωú‰∏öÁîüÂëΩÂë®Êúü
"""

import os
import subprocess
from datetime import datetime
from pathlib import Path

from loguru import logger

from core.config import get_settings
from core.database import sync_db
from core.models import Job, ResourceAllocation
from core.enums import JobState, ResourceStatus
from core.services import ResourceManager

from worker.process_utils import store_pid, kill_process_tree


class JobExecutor:
    """
    ‰Ωú‰∏öÊâßË°åÂô®

    ÈáçÊûÑËØ¥ÊòéÔºö
    - ‰ΩøÁî® ResourceManager ÁÆ°ÁêÜËµÑÊ∫êÈáäÊîæ
    - ÈÅµÂæ™ DRY ÂéüÂàô
    """

    def __init__(self, resource_manager: ResourceManager = None):
        """
        ÂàùÂßãÂåñÊâßË°åÂô®

        Args:
            resource_manager: ËµÑÊ∫êÁÆ°ÁêÜÂô®ÔºàÂèØÈÄâÔºåÁî®‰∫é‰æùËµñÊ≥®ÂÖ•Ôºâ
        """
        self.settings = get_settings()
        self.resource_manager = resource_manager or ResourceManager()

    def execute(self, job_id: int):
        """
        ÊâßË°å‰Ωú‰∏ö

        Args:
            job_id: ‰Ωú‰∏ö ID
        """
        logger.info(f"üöÄ Executing job {job_id}")

        exit_code = None
        error_occurred = False
        error_msg = None

        try:
            # Âä†ËΩΩ‰Ωú‰∏ö
            job = self._load_job(job_id)

            # È™åËØÅÁä∂ÊÄÅ
            if job.state != JobState.RUNNING:
                logger.error(
                    f"Job {job_id} state is {job.state.value}, expected RUNNING"
                )
                return

            # ÈáçË¶ÅÔºöÂú®ÁúüÊ≠£ÂºÄÂßãÊâßË°åÂâçÔºåÂ∞ÜËµÑÊ∫êÁä∂ÊÄÅ‰ªé reserved Êõ¥Êñ∞‰∏∫ allocated
            # ËøôÊ†∑ÊâçÁÆóÁúüÊ≠£Âç†Áî®ËµÑÊ∫ê
            self._mark_resources_allocated(job_id, job.allocated_cpus)

            # ÊâßË°å‰Ωú‰∏ö
            exit_code = self._run(job)

        except Exception as e:
            logger.error(f"‚ùå Job {job_id} failed: {e}", exc_info=True)
            error_occurred = True
            error_msg = str(e)

        finally:
            # ÈáçË¶ÅÔºöÂÖàÈáäÊîæËµÑÊ∫êÔºåÂÜçÊõ¥Êñ∞Áä∂ÊÄÅ
            # ÈÅøÂÖç scheduler ÁöÑ release_completed() Êä¢ÂÖàÈáäÊîæËµÑÊ∫ê
            self._release_resources(job_id)

            # Êõ¥Êñ∞ÊúÄÁªàÁä∂ÊÄÅ
            if error_occurred:
                self._mark_failed(job_id, error_msg)
            elif exit_code is not None:
                self._update_completion(job_id, exit_code)

            logger.info(f"‚úÖ Job {job_id} finished")

    def _load_job(self, job_id: int) -> Job:
        """Âä†ËΩΩ‰Ωú‰∏ö‰ø°ÊÅØ"""
        with sync_db.get_session() as session:
            job = session.query(Job).filter(Job.id == job_id).first()
            if not job:
                raise ValueError(f"Job {job_id} not found")
            session.expunge(job)
            return job

    def _run(self, job: Job) -> int:
        """ËøêË°å‰Ωú‰∏öËÑöÊú¨"""
        logger.info(f"Running job {job.id}: {job.name}")

        # ÂáÜÂ§áÁéØÂ¢É
        script_path = self._prepare_script(job)
        stdout_path = Path(job.work_dir) / job.stdout_path
        stderr_path = Path(job.work_dir) / job.stderr_path

        # ÂáÜÂ§áÁéØÂ¢ÉÂèòÈáè
        env = os.environ.copy()
        if job.environment:
            env.update(job.environment)

        # ÊâßË°åËÑöÊú¨
        try:
            with open(stdout_path, "w") as stdout, open(stderr_path, "w") as stderr:
                process = subprocess.Popen(
                    ["/bin/bash", script_path],
                    stdout=stdout,
                    stderr=stderr,
                    cwd=job.work_dir,
                    env=env,
                    preexec_fn=os.setsid,
                )

                # ËÆ∞ÂΩïËøõÁ®ã ID
                store_pid(job.id, process.pid)
                logger.info(f"Job {job.id} started, PID: {process.pid}")

                # Á≠âÂæÖÂÆåÊàêÔºàÊîØÊåÅË∂ÖÊó∂Ôºâ
                try:
                    timeout = job.time_limit * 60 if job.time_limit else None
                    exit_code = process.wait(timeout=timeout)
                except subprocess.TimeoutExpired:
                    logger.warning(f"Job {job.id} timeout, terminating...")
                    kill_process_tree(process.pid, timeout=5)
                    exit_code = -1

                logger.info(f"Job {job.id} finished, exit code: {exit_code}")
                return exit_code

        except Exception as e:
            logger.error(f"Failed to run job {job.id}: {e}")
            raise

    def _prepare_script(self, job: Job) -> str:
        """ÂáÜÂ§áËÑöÊú¨Êñá‰ª∂"""
        # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
        Path(job.work_dir).mkdir(parents=True, exist_ok=True)

        # ÂÜôÂÖ•ËÑöÊú¨
        script_path = Path(self.settings.SCRIPT_DIR) / f"job_{job.id}.sh"
        script_path.parent.mkdir(parents=True, exist_ok=True)

        script_path.write_text(job.script)
        script_path.chmod(0o755)

        return str(script_path)

    def _update_completion(self, job_id: int, exit_code: int):
        """Êõ¥Êñ∞‰Ωú‰∏öÂÆåÊàêÁä∂ÊÄÅ"""
        with sync_db.get_session() as session:
            job = session.query(Job).filter(Job.id == job_id).first()
            if job:
                job.state = JobState.COMPLETED if exit_code == 0 else JobState.FAILED
                job.end_time = datetime.utcnow()
                job.exit_code = f"{exit_code}:0"

                if exit_code != 0:
                    job.error_msg = f"Exited with code {exit_code}"

                session.commit()
                logger.info(f"Job {job_id} marked as {job.state.value}")

    def _mark_failed(self, job_id: int, error_msg: str):
        """Ê†áËÆ∞‰Ωú‰∏öÂ§±Ë¥•"""
        try:
            with sync_db.get_session() as session:
                job = session.query(Job).filter(Job.id == job_id).first()
                if job:
                    job.state = JobState.FAILED
                    job.end_time = datetime.utcnow()
                    job.error_msg = error_msg
                    job.exit_code = "-1:0"
                    session.commit()
        except Exception as e:
            logger.error(f"Failed to mark job {job_id} as failed: {e}")

    def _mark_resources_allocated(self, job_id: int, cpus: int):
        """
        Â∞ÜËµÑÊ∫êÁä∂ÊÄÅ‰ªé reserved Êõ¥Êñ∞‰∏∫ allocated
        
        ËøôÊòØËµÑÊ∫êÁúüÊ≠£Ë¢´Âç†Áî®ÁöÑÊó∂ÂàªÔºåÂè™ÊúâÂú® Worker ÁúüÊ≠£ÂºÄÂßãÊâßË°å‰Ωú‰∏öÊó∂ÊâçË∞ÉÁî®„ÄÇ
        ËøôÊ†∑ÂèØ‰ª•ÈÅøÂÖç‰Ωú‰∏öË¢´Ë∞ÉÂ∫¶‰ΩÜÊú™ÂÆûÈôÖËøêË°åÂØºËá¥ÁöÑËµÑÊ∫êÊ≥ÑÊºèÈóÆÈ¢ò„ÄÇ

        Args:
            job_id: ‰Ωú‰∏ö ID
            cpus: CPU Êï∞Èáè
        """
        with sync_db.get_session() as session:
            allocation = (
                session.query(ResourceAllocation)
                .filter(ResourceAllocation.job_id == job_id)
                .first()
            )

            if allocation:
                # Êõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ allocated
                allocation.status = ResourceStatus.ALLOCATED
                session.commit()

                # Êõ¥Êñ∞ Redis ÁºìÂ≠òÔºàÁé∞Âú®ËµÑÊ∫êÊâçÁúüÊ≠£Ë¢´Âç†Áî®Ôºâ
                self.resource_manager.allocate(cpus)

                logger.info(
                    f"‚úÖ Resources allocated for job {job_id}: {cpus} CPUs "
                    f"(status: reserved -> allocated)"
                )
            else:
                logger.warning(
                    f"‚ö†Ô∏è  No resource allocation found for job {job_id}, "
                    f"creating new allocation"
                )
                # Â¶ÇÊûúÊ≤°ÊúâÈ¢ÑÁïôËÆ∞ÂΩïÔºàÂºÇÂ∏∏ÊÉÖÂÜµÔºâÔºåÁõ¥Êé•ÂàõÂª∫ allocated ËÆ∞ÂΩï
                allocation = ResourceAllocation(
                    job_id=job_id,
                    allocated_cpus=cpus,
                    node_name=self.settings.NODE_NAME,
                    allocation_time=datetime.utcnow(),
                    status=ResourceStatus.ALLOCATED,
                )
                session.add(allocation)
                session.commit()
                self.resource_manager.allocate(cpus)

    def _release_resources(self, job_id: int):
        """
        ÈáäÊîæËµÑÊ∫êÔºàÊõ¥Êñ∞Êï∞ÊçÆÂ∫ì + Redis ÁºìÂ≠òÔºâ
        
        Êõ¥Êñ∞Áä∂ÊÄÅ‰∏∫ releasedÔºåÂπ∂ÂõûÊî∂ËµÑÊ∫êÂà∞ÂèØÁî®Ê±†

        Args:
            job_id: ‰Ωú‰∏ö ID
        """
        with sync_db.get_session() as session:
            # Êü•ÊâæÊú™ÈáäÊîæÁöÑËµÑÊ∫êÂàÜÈÖçËÆ∞ÂΩïÔºàstatus != releasedÔºâ
            allocation = (
                session.query(ResourceAllocation)
                .filter(
                    ResourceAllocation.job_id == job_id,
                    ResourceAllocation.status != ResourceStatus.RELEASED,
                )
                .first()
            )

            if allocation:
                cpus = allocation.allocated_cpus
                old_status = allocation.status

                # 1. Êõ¥Êñ∞Áä∂ÊÄÅ‰∏∫Â∑≤ÈáäÊîæ
                allocation.status = ResourceStatus.RELEASED
                allocation.released_time = datetime.utcnow()
                session.commit()

                # 2. Âè™ÊúâÂú®ËµÑÊ∫êÂÆûÈôÖË¢´ÂàÜÈÖçÊó∂ÔºàallocatedÔºâÊâçÈúÄË¶ÅÊõ¥Êñ∞ÁºìÂ≠ò
                # Â¶ÇÊûúËøòÊòØ reserved Áä∂ÊÄÅÂ∞±Ë¢´ÈáäÊîæ‰∫ÜÔºåËØ¥Êòé‰ªéÊú™ÁúüÊ≠£Âç†Áî®Ôºå‰∏çÈúÄË¶ÅÈáäÊîæÁºìÂ≠ò
                if old_status == ResourceStatus.ALLOCATED:
                    self.resource_manager.release(cpus)
                    logger.info(
                        f"‚ôªÔ∏è  Released {cpus} CPUs for job {job_id} "
                        f"(status: allocated -> released)"
                    )
                else:
                    logger.info(
                        f"‚ôªÔ∏è  Released reservation for job {job_id} "
                        f"(status: {old_status} -> released, no cache update needed)"
                    )
            else:
                logger.warning(
                    f"‚ö†Ô∏è  No unreleased allocation found for job {job_id}"
                )


# RQ ‰ªªÂä°ÂÖ•Âè£
def execute_job(job_id: int):
    """
    RQ ‰ªªÂä°ÂáΩÊï∞

    Args:
        job_id: ‰Ωú‰∏ö ID
    """
    executor = JobExecutor()
    executor.execute(job_id)
